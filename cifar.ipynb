{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports & Initializations.\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import csv\n",
    "import itertools\n",
    "import json\n",
    "import os\n",
    "import pickle\n",
    "import sys\n",
    "import time\n",
    "from pathlib import Path\n",
    "from scipy.stats import spearmanr\n",
    "\n",
    "import comet_ml\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import yaml\n",
    "from aim import Repo\n",
    "from naapc import NDict\n",
    "from tqdm import tqdm\n",
    "\n",
    "from query_configs import cifar_normal, cifar_normal_numes\n",
    "from stracker.ana import get_metric_value_of_aim_run, get_repeated_missing_seeds, query, get_metric_names_of_aim_run, filt_aim_repeated_runs\n",
    "\n",
    "check_repeat_ops = {\n",
    "    \"delete_repeat\": False,\n",
    "    \"archive_repeat\": False,\n",
    "}\n",
    "\n",
    "result_path = Path() / \"results\"\n",
    "result_path.mkdir(exist_ok=True, parents=True)\n",
    "aim_path = Path(\"/Users/ei/Documents/aim/crowdsourcing\")\n",
    "repo = Repo(str(aim_path))\n",
    "run = next(repo.iter_runs())\n",
    "hash_hparams = {run.hash: NDict(run[\"hparams\"]) for run in repo.iter_runs()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cifar:olrandom-split10-ftmiss: [3]\n",
      "cifar:olrandom-split100-ftmiss: [3, 4]\n",
      "cifar:olrandom-split100-lwfmiss: [5]\n"
     ]
    }
   ],
   "source": [
    "# Check for cifar olrandom.\n",
    "task = \"olrandom\"\n",
    "filt_option = \"latest\"\n",
    "check_repeat_ops[\"archive_repeat\"] = False\n",
    "seeds = [1, 2, 3, 4, 5]\n",
    "trainer_configs = cifar_normal\n",
    "splits = [10, 50, 100]\n",
    "saving_hashes = {split: {} for split in splits}\n",
    "for (tr, config), split in itertools.product(trainer_configs.items(), splits):\n",
    "    config[\"data;split\"] = split\n",
    "    config[\"task;task\"] = task\n",
    "    config[\"train;plateau_metric\"] = \"QUERY v in ['acc', 'train_acc']\"\n",
    "    config[\"task;seed\"] = f\"QUERY v in {seeds}\"\n",
    "\n",
    "    prefix_info = f\"cifar:olrandom-split{split}-{tr} \"\n",
    "    metas = query(hash_hparams, config, missing_path_action=\"ignore\")\n",
    "    repetitions, missing = get_repeated_missing_seeds(metas, \"task;seed\", seeds, verbose=True, prefix=prefix_info)\n",
    "    runs = [repo.get_run(h) for h in metas.keys()]\n",
    "    if repetitions:\n",
    "        repetitions = {s: [repo.get(h) for h in hashes] for s, hashes in repetitions.items()}\n",
    "    runs = filt_aim_repeated_runs(runs, repetitions)\n",
    "    saving_hashes[split][tr] = [run.hash for run in runs]\n",
    "\n",
    "with open(result_path / \"cifar-olrandom-hash.yaml\", \"w\") as f:\n",
    "    yaml.dump(saving_hashes, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cifar olrandom test_batch_acc\n",
    "with open(result_path / \"cifar-olrandom-hashes.yaml\", \"r\") as f:\n",
    "    keys = yaml.safe_load(f)\n",
    "\n",
    "splits = [10, 50, 100]\n",
    "seeds = [1, 2, 3, 4, 5]\n",
    "gen_results = True\n",
    "if gen_results:\n",
    "    results = {split: {} for split in splits}\n",
    "    for split, shashes in keys.items():\n",
    "        for tr, hs in shashes.items():\n",
    "            runs = [repo.get_run(h) for h in hs]\n",
    "            assert {NDict(run[\"hparams\"])[\"task;seed\"] for run in runs} == set(seeds)\n",
    "            print(split, tr, hs, get_metric_value_of_aim_run(run, \"test_batch_acc\"))\n",
    "            metrics = np.concatenate(\n",
    "                [np.array(get_metric_value_of_aim_run(run, \"test_batch_acc\")).reshape(1, -1) for run in runs], axis=0\n",
    "            )\n",
    "            assert metrics.shape[0] == len(seeds)\n",
    "            mean_metrics = metrics.mean(axis=0)\n",
    "            all_metrics = {\n",
    "                \"batch\": mean_metrics.tolist(),\n",
    "                \"inc\": mean_metrics.mean().item(),\n",
    "                \"fin\": mean_metrics[-1].item(),\n",
    "                \"spearmanc\": spearmanr(\n",
    "                    mean_metrics, list(range(mean_metrics.size))\n",
    "                ).correlation.item(),\n",
    "                \"spearmanp\": spearmanr(\n",
    "                    mean_metrics, list(range(mean_metrics.size))\n",
    "                ).pvalue.item(),\n",
    "            }\n",
    "            results[split][tr] = all_metrics\n",
    "    with open(result_path / \"cifar-olrandom-metrics.yaml\", \"w\") as f:\n",
    "        yaml.dump(results, f)\n",
    "else:\n",
    "    with open(result_path / \"cifar-olrandom-metrics.yaml\", \"r\") as f:\n",
    "        results = yaml.safe_load(f)\n",
    "\n",
    "for split, sms in results.items():\n",
    "    # plot_metrics({tr: m[\"batch\"] for tr, m in sms.items()}, f\"cifar-olrandom-{split}\", \"step\", \"acc\")\n",
    "    plt.figure()\n",
    "    plt.title(f\"cifar-olrandom-{split}\")\n",
    "    plt.xlabel(\"step\")\n",
    "    plt.ylabel(\"acc\")\n",
    "    metrics = {tr: m[\"batch\"] for tr, m in sms.items()}\n",
    "    for k, ms in metrics.items():\n",
    "        step = list(range(1, len(ms) + 1))\n",
    "        plt.plot(step, ms, label=k)\n",
    "    plt.legend()\n",
    "    plt.grid()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for cifar num_e.\n",
    "pro.update_dbs()\n",
    "check_repeat_ops[\"archive_repeat\"] = False\n",
    "\n",
    "task = \"olrandom\"\n",
    "seeds = [1, 2, 3, 4, 5]\n",
    "\n",
    "task = \"olrandom\"\n",
    "check_repeat_ops[\"archive_repeat\"] = False\n",
    "seeds = [1, 2, 3, 4, 5]\n",
    "splits = cifar_splits[\"olrandom\"]\n",
    "splits = [10]\n",
    "config = cifar_normal[\"eeol\"]\n",
    "config[\"data;split\"] = 10\n",
    "config[\"log;note\"] = \"small_dist0.5\"\n",
    "config[\"task;task\"] = \"olrandom\"\n",
    "saving_keys = {}\n",
    "\n",
    "num_es = [x * 10 for x in range(1, 21)]\n",
    "\n",
    "saving_keys = {}\n",
    "# for p, smooth, losst, suppress in itertools.product(prompts, smooths, lossts, suppresses):\n",
    "cnt = 0\n",
    "for num_e in num_es:\n",
    "    config[\"train;plateau_metric\"] = lambda v, config: v in [\"acc\", \"train_acc\"]\n",
    "    config[\"task;num_exemplars_per_class\"] = num_e\n",
    "\n",
    "    prefix_info = f\"cifar:{task}-num_e{num_e}\"\n",
    "    keys, repeated, missing = deal_seeds(pro, config, prefix_info, seeds, check_repeat_ops, True)\n",
    "\n",
    "    if len(missing) == 0:\n",
    "        saving_keys[num_e] = list(keys)\n",
    "    else:\n",
    "        cnt += len(missing)\n",
    "print(f\"Missing {cnt} in total.\")\n",
    "# saving_keys[\"configs\"] = config\n",
    "with open(result_path / \"cifar-olrandom-eeol-num_e-keys.yaml\", \"w\") as f:\n",
    "    yaml.dump(saving_keys, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cifar num_e test_batch_acc\n",
    "# pro.update_dbs()\n",
    "with open(result_path / \"cifar-olrandom-eeol-num_e-keys.yaml\", \"r\") as f:\n",
    "    keys = yaml.safe_load(f)\n",
    "\n",
    "# splits = cifar_splits[\"olrandom\"]\n",
    "seeds = [1, 2, 3, 4, 5]\n",
    "gen_results = True\n",
    "if gen_results:\n",
    "    results = {}\n",
    "    for num_e, ks in keys.items():\n",
    "        exps = [pro.get(k) for k in ks]\n",
    "        results[num_e] = get_metrics(exps, seeds)\n",
    "    with open(result_path / \"cifar-olrandom-eeol-num_e-result.csv\", \"w\") as f:\n",
    "        heads = \",\".join([f\"num_e{num_e}\" for num_e in keys.keys()] + [f\"num_e{num_e}_fin\" for num_e in keys.keys()] + [f\"num_e{num_e}_inc\" for num_e in keys.keys()]) + \"\\n\"\n",
    "        f.write(heads)\n",
    "        for i in range(20):\n",
    "            tmp = [str(results[num_e][\"batch\"][i]) for num_e in results]\n",
    "            if i == 0:\n",
    "                tmp += [str(results[num_e][\"fin\"]) for num_e in results]\n",
    "                tmp += [str(results[num_e][\"inc\"]) for num_e in results]\n",
    "            f.write(\",\".join(tmp) + \"\\n\")\n",
    "    with open(result_path / \"cifar-olrandom-eeol-num_e-result.yaml\", \"w\") as f:\n",
    "        yaml.dump(results, f)\n",
    "else:\n",
    "    with open(result_path / \"cifar-olrandom-eeol-num_e-result.yaml\", \"r\") as f:\n",
    "        results = yaml.safe_load(f)\n",
    "\n",
    "fins = sorted([[num_e, m[\"fin\"]] for num_e, m in results.items()], key=lambda x: x[0])\n",
    "incs = sorted([[num_e, m[\"inc\"]] for num_e, m in results.items()], key=lambda x: x[0])\n",
    "\n",
    "plt.figure()\n",
    "num_e, fin = zip(*fins)\n",
    "plt.plot(num_e, fin, label=\"final\")\n",
    "num_e, inc = zip(*incs)\n",
    "plt.plot(num_e, inc, label=\"incremental\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('torch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d35f56726c01aab56b6bea21bc3bb025a63c9c38a39cf7837bd6bc0801634f6b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
